{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "First implementation on deep nn using mnist dataset.\n",
    "This code is based on the Chapter 8 implementation of Grokking Deep Learning book\n",
    "\n",
    "- implementation has overfitting issues\n",
    "\n",
    "- implementation uses stochastic gradient descent (compute gradient for one training example at a time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:0 Error:0.722 Correct:0.537\n",
      " Test-Err:0.601 Test-Acc:0.6488\n",
      "\n",
      " I:10 Error:0.312 Correct:0.901\n",
      " Test-Err:0.420 Test-Acc:0.8114\n",
      "\n",
      " I:20 Error:0.260 Correct:0.937\n",
      " Test-Err:0.414 Test-Acc:0.8111\n",
      "\n",
      " I:30 Error:0.232 Correct:0.946\n",
      " Test-Err:0.417 Test-Acc:0.8066\n",
      "\n",
      " I:40 Error:0.215 Correct:0.956\n",
      " Test-Err:0.426 Test-Acc:0.8019\n",
      "\n",
      " I:50 Error:0.204 Correct:0.966\n",
      " Test-Err:0.437 Test-Acc:0.7982\n",
      "\n",
      " I:60 Error:0.194 Correct:0.967\n",
      " Test-Err:0.448 Test-Acc:0.7921\n",
      "\n",
      " I:70 Error:0.186 Correct:0.975\n",
      " Test-Err:0.458 Test-Acc:0.7864\n",
      "\n",
      " I:80 Error:0.179 Correct:0.979\n",
      " Test-Err:0.466 Test-Acc:0.7817\n",
      "\n",
      " I:90 Error:0.172 Correct:0.981\n",
      " Test-Err:0.474 Test-Acc:0.7758\n",
      "\n",
      " I:100 Error:0.166 Correct:0.984\n",
      " Test-Err:0.482 Test-Acc:0.7706\n",
      "\n",
      " I:110 Error:0.161 Correct:0.984\n",
      " Test-Err:0.489 Test-Acc:0.7686\n",
      "\n",
      " I:120 Error:0.157 Correct:0.986\n",
      " Test-Err:0.496 Test-Acc:0.766\n",
      "\n",
      " I:130 Error:0.153 Correct:0.999\n",
      " Test-Err:0.502 Test-Acc:0.7622\n",
      "\n",
      " I:140 Error:0.149 Correct:0.991\n",
      " Test-Err:0.508 Test-Acc:0.758\n",
      "\n",
      " I:150 Error:0.145 Correct:0.991\n",
      " Test-Err:0.513 Test-Acc:0.7558\n",
      "\n",
      " I:160 Error:0.141 Correct:0.992\n",
      " Test-Err:0.518 Test-Acc:0.7553\n",
      "\n",
      " I:170 Error:0.138 Correct:0.992\n",
      " Test-Err:0.524 Test-Acc:0.751\n",
      "\n",
      " I:180 Error:0.135 Correct:0.995\n",
      " Test-Err:0.528 Test-Acc:0.7505\n",
      "\n",
      " I:190 Error:0.132 Correct:0.995\n",
      " Test-Err:0.533 Test-Acc:0.7482\n",
      "\n",
      " I:200 Error:0.130 Correct:0.998\n",
      " Test-Err:0.538 Test-Acc:0.7464\n",
      "\n",
      " I:210 Error:0.127 Correct:0.998\n",
      " Test-Err:0.544 Test-Acc:0.7446\n",
      "\n",
      " I:220 Error:0.125 Correct:0.998\n",
      " Test-Err:0.552 Test-Acc:0.7416\n",
      "\n",
      " I:230 Error:0.123 Correct:0.998\n",
      " Test-Err:0.560 Test-Acc:0.7372\n",
      "\n",
      " I:240 Error:0.121 Correct:0.998\n",
      " Test-Err:0.569 Test-Acc:0.7344\n",
      "\n",
      " I:250 Error:0.120 Correct:0.999\n",
      " Test-Err:0.577 Test-Acc:0.7316\n",
      "\n",
      " I:260 Error:0.118 Correct:0.999\n",
      " Test-Err:0.585 Test-Acc:0.729\n",
      "\n",
      " I:270 Error:0.117 Correct:0.999\n",
      " Test-Err:0.593 Test-Acc:0.7259\n",
      "\n",
      " I:280 Error:0.115 Correct:0.999\n",
      " Test-Err:0.600 Test-Acc:0.723\n",
      "\n",
      " I:290 Error:0.114 Correct:0.999\n",
      " Test-Err:0.607 Test-Acc:0.7196\n",
      "\n",
      " I:299 Error:0.113 Correct:0.999\n",
      " Test-Err:0.614 Test-Acc:0.7183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "#from IPython.core.debugger import Tracer; Tracer()()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "def relu(x):\n",
    "    return (x >= 0) * x\n",
    "\n",
    "def relu2deriv(x):\n",
    "    return x >= 0\n",
    "\n",
    "alpha = 0.005\n",
    "iterations = 300\n",
    "neurons = 40\n",
    "pixels = 784\n",
    "num_labels = 10\n",
    "\n",
    "weights_0_1 = 0.2 * np.random.random((pixels, neurons)) - 0.1\n",
    "weights_1_2 = 0.2 * np.random.random((neurons, num_labels)) - 0.1\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    \n",
    "    error = 0.0\n",
    "    correct_count = 0\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        \n",
    "        layer_0 = images[i:i+1]\n",
    "        \n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        \n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        error += np.sum( (labels[i:i+1] - layer_2) ** 2)\n",
    "        \n",
    "        correct_count += int( np.argmax(layer_2)  == np.argmax(labels[i:i+1]) )\n",
    "        \n",
    "        layer_2_delta = labels[i:i+1] - layer_2\n",
    "        \n",
    "        layer_1_delta = np.dot(layer_2_delta, weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 += alpha * (np.dot(layer_1.T, layer_2_delta))\n",
    "        weights_0_1 += alpha * (np.dot(layer_0.T, layer_1_delta))\n",
    "        \n",
    "    sys.stdout.write(\"\\r\"+ \\\n",
    "    \" I:\"+str(iteration)+ \\\n",
    "    \" Error:\" + str(error/float(len(images)))[0:5] +\\\n",
    "    \" Correct:\" + str(correct_count/float(len(images))))\n",
    "    \n",
    "    \n",
    "    if(iteration % 10 == 0 or iteration == iterations-1):\n",
    "        error, correct_cnt = (0.0, 0)\n",
    "        print()\n",
    "        for i in range(len(test_images)):\n",
    "\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "            error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                            np.argmax(test_labels[i:i+1]))\n",
    "        sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] +\\\n",
    "                         \" Test-Acc:\" + str(correct_cnt/float(len(test_images))) + \"\\n\")    \n",
    "        print()\n",
    "    #from IPython.core.debugger import Tracer; Tracer()()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
